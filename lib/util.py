import numpy as np
import functools
import itertools

sawtooth = {
        'a': np.array([7.1, 7.1, 0.9, 7.1, 0.9, 7.1, 0.9]),
        'b': np.array([7.1, 0.9, 7.1, 0.9, 7.1, 0.9, 0.9]),
        's_gen': np.array([1000.0, 4000.0 - 1000., 10500. - 4000., 65000. - 10500., 115000. - 65000., 1e6 - 115000, 1.0]) / 25.0
        }

humany = {
    'a': np.array([10.0, 0.5, 1.0, 2.0, 3.0]),
    'b': np.array([1.0, 0.5, 1.0, 2.0, 3.0]),
    's_gen': np.array([10000., 70000. - 10000., 150000. - 70000., 1.0]) / 25.0
    }

def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx
    args = [iter(iterable)] * n
    return itertools.izip_longest(fillvalue=fillvalue, *args)

def unpack(iterable):
    for span, x in iterable:
        for i in range(span):
            yield x

def pack(seq):
    iterable = iter(seq)
    x = next(iterable)
    i = 1
    for xp in iterable:
        if xp == x:
            i += 1
        else:
            yield (i, x)
            x = xp
            i = 1
    yield (i, x)

def memoize(obj):
    cache = obj.cache = {}
    @functools.wraps(obj)
    def memoizer(*args, **kwargs):
        key = tuple(args) + tuple(kwargs.items())
        if key not in cache:
            cache[key] = obj(*args, **kwargs)
        return cache[key]
    return memoizer

def kl(sfs1, sfs2):
    s1 = sfs1.flatten()
    s2 = sfs2.flatten()
    nz = s1 != 0.0
    return (s1[nz] * (np.log(s1[nz]) - np.log(s2[nz]))).sum()

def dataset_from_panel(dataset, n, distinguished_rows, random=True):
    L, positions, haps = dataset[:3]
    dr = list(distinguished_rows)
    K = haps.shape[1]
    if n < haps.shape[0]:
        panel = haps[[i for i in range(haps.shape[0]) if i not in dr]]
        N, K = panel.shape
        h2 = np.zeros([n, K], dtype=np.int8)
        h2[:2] = haps[dr]
        for i in range(K):
            inds = [j for j in range(N) if j not in dr and panel[j, i] != -1]
            if random:
                inds = np.random.permutation(inds)
            assert len(inds) >= n - 2
            h2[2:, i] = panel[:, i][inds[:(n - 2)]]
        haps = h2
    else:
        perm = np.arange(n)
        perm[[0, 1] + dr] = perm[dr + [0, 1]]
        haps = haps[np.ix_(perm, np.arange(K))]
    seg = np.logical_and(*[(haps != a).sum(axis=0) > 0 for a in [0, 1]])
    return (L, positions[seg], haps[:, seg]) + dataset[3:]

def hmm_data_format(dataset, n, distinguished_rows):
    # Convert a dataset generated by simulate() to the format accepted
    # by the inference code
    ret = []
    p = 0
    L, positions, haps = dataset_from_panel(dataset, n, distinguished_rows)[:3]
    d = haps[:2].sum(axis=0)
    d[haps[:2].min(axis=0) == -1] = -1
    t = haps[2:].sum(axis=0)
    if n > 2:
        t[haps[2:].min(axis=0) == -1] = -1
    nd = d.shape[0]
    nrow = 2 * nd - 1
    ret = np.zeros([nrow, 3], dtype=int)
    ret[::2, 0] = 1
    ret[::2, 1] = d
    ret[::2, 2] = t
    gaps = positions[1:] - positions[:-1] - 1
    ret[1::2, 0] = gaps
    ret[1::2, 1:] = 0
    if positions[0] > 0:
        ret = np.vstack(([positions[0], 0, 0], ret))
    if positions[-1] < L - 1:
        ret = np.vstack((ret, [L - 1 - positions[-1], 0, 0]))
    # eliminate "no gaps"
    ret = ret[ret[:, 0] > 0]
    # assert np.all(ret >= 0)
    assert ret.sum(axis=0)[0] == L, (L, ret.sum(axis=0)[0], ret)
    ret = np.array(ret, dtype=np.int32)
    assert ret.sum(axis=0)[0] == L
    assert np.all(ret[:, 0] >= 1)
    return ret

def config2dict(cp):
    return {sec: dict(cp.items(sec)) for sec in cp.sections()}
