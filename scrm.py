from __future__ import division
import bitarray
import numpy as np
import math
import os
import sh
from subprocess import check_output
import subprocess
import itertools
import logging
import sys

from Bio import Phylo
from cStringIO import StringIO
import networkx as nx

logger = logging.getLogger(__name__)

scrm = sh.Command(os.environ['SCRM_PATH'])

def demography_from_params(params):
    demography = []
    ct = 0.0
    for ai, bi, si in zip(*params):
        si2 = si * 0.5
        beta = (ai - bi) / si2
        demography += ['-eN', ct, np.exp(ai)]
        if beta != 0.0:
            demography += ['-eG', ct, beta]
        ct += si2
    return demography

def print_data_stats(positions, haps):
    gaps = positions[1:] - positions[:-1]
    print("Minimum gap: %d" % np.min(gaps))
    print("Average gap: %d" % np.mean(gaps))
    print("# seg. sites: %d" % gaps.shape[0])
    i = np.argmin(gaps)
    print(positions[(i-3):(i+3)])

def parse_scrm(n, L, output, include_trees):
    cmd_line, seed, _, _ = [line.strip() for line in itertools.islice(output, 4)]
    coal_times = []
    ts = 0
    for line in output:
        if line.startswith("segsites"):
            break
        if not include_trees:
            continue
        l = line.strip()
        k = l.index("(") - 1
        span = int(l[1:k])
        ts += span
        tree = Phylo.to_networkx(Phylo.read(StringIO(l[k:]), "newick"))
        leaves = {node.confidence: node for node in tree.nodes() 
                if node.confidence}
        dsts = {}
        all_dsts = nx.shortest_path_length(tree, weight='weight')
        for n1, n2 in itertools.combinations(leaves, 2):
            dsts[frozenset([n1, n2])] = all_dsts[leaves[n1]][leaves[n2]] / 2.0
        coal_times.append((span, dsts))
    positions = next(output).strip()
    if positions:
        positions = (L * np.array([float(x) for x in positions.split(" ")[1:]])).astype('int')
        # ignore trailing newline
        haps = [bitarray.bitarray(str(line).strip()) for line in output if line.strip()] 
        ret = (L, positions, haps)
        if include_trees:
            ret += (coal_times,)
        return ret
    return None

def simulate(n, N0, theta, rho, L, demography=[], include_trees=False):
    r = 4 * N0 * rho * (L - 1)
    t = 4 * N0 * theta * L
    args = [n, 1, '-p', int(math.log10(L)) + 1, '-t', t, '-r', r, L, '-l', 
            1000, '-T', '-seed', np.random.randint(0, sys.maxint)] + demography
    output = scrm(*args, _iter=True)
    return parse_scrm(n, L, output, include_trees)

def sfs(n, M, N0, theta, demography=[]):
    t = 4 * N0 * theta
    args = [n, M, '-t', t, '-oSFS'] + demography
    cmd = os.environ['SCRM_PATH'] + " " + " ".join(map(str, args))
    output = check_output(
            """%s | grep SFS | tail -n+2 | cut -f2- -d' ' | Rscript -e 'cat(colSums(read.table(file("stdin"))))'""" % cmd, shell=True)
    ret = np.array([float(x) for x in output.split()])
    assert ret.shape == (n - 1,)
    ret = np.append([M - ret.sum(),], ret)
    assert ret.sum() == M
    return ret

def hmm_data_format(dataset, distinguished_cols):
    # Convert a dataset generated by simulate() to 
    # the format accepted by the inference code
    ret = []
    p = 0
    L, positions, haps = dataset[:3]
    for i, pos in enumerate(positions):
        pp = pos - p
        if pp == 0:
            logger.warn("Tri-allelic site at position %d; ignoring" % pos)
            continue
        if pp > 1:
            ret.append([pp - 1, 0, 0])
        d = sum([haps[c][i] for c in distinguished_cols])
        t = sum([h[i] for h in haps])
        ret.append([1, d, t - d])
        p = pos
    if L > pos:
        ret.append([L - pos, 0, 0])
    return np.array(ret, dtype=np.int32)

if __name__ == "__main__":
    L = 1000000
    data = simulate(50, 10000.0, 1e-8, 1e-8, L, ['-n', 1, 1])
    hmmd = hmm_data_format(data, (0, 1))
